{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Noisy Images: 100%|██████████| 20/20 [00:00<00:00, 3134.76it/s]\n",
      "Denoising Frames: 100%|██████████| 20/20 [00:00<00:00, 1092.01it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to add black and white (salt-and-pepper) noise to an image\n",
    "def add_black_and_white_noise(image, noise_factor=0.05):\n",
    "    row, col, ch = image.shape\n",
    "    # Create a random noise matrix for black and white noise\n",
    "    noisy_image = np.copy(image)\n",
    "    # Salt noise (white pixels)\n",
    "    salt = np.random.rand(row, col) < noise_factor  # Only grayscale noise matrix\n",
    "    noisy_image[salt] = [255, 255, 255]  # Set salt (white) pixels to 255 in all channels\n",
    "    # Pepper noise (black pixels)\n",
    "    pepper = np.random.rand(row, col) < noise_factor  # Only grayscale noise matrix\n",
    "    noisy_image[pepper] = [0, 0, 0]  # Set pepper (black) pixels to 0 in all channels\n",
    "    return noisy_image\n",
    "\n",
    "# Function to denoise an image using GaussianBlur\n",
    "def denoise_image(image):\n",
    "    return cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "# Load the image (make sure you replace 'cat.png' with the path to your image)\n",
    "image = cv2.imread('cat.png')\n",
    "\n",
    "# Convert the image to RGB (OpenCV loads it as BGR)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Create a list to store noisy images (most noisy first)\n",
    "noisy_images = []\n",
    "\n",
    "# Generate noisy images in reverse order (most noisy first)\n",
    "for i in tqdm(range(20, 0, -1), desc=\"Generating Noisy Images\"):\n",
    "    noisy_images.append(add_black_and_white_noise(image_rgb, noise_factor=i*0.05))\n",
    "\n",
    "# Create a list to store the denoised frames for the GIF\n",
    "frames = []\n",
    "\n",
    "# Denoise the images progressively and store them as frames\n",
    "for noisy_image in tqdm(noisy_images, desc=\"Denoising Frames\"):\n",
    "    denoise_image_step = denoise_image(noisy_image)\n",
    "    frames.append(Image.fromarray(denoise_image_step))\n",
    "\n",
    "# Save the animated GIF\n",
    "frames[0].save('cat_denoise_reversed.gif', save_all=True, append_images=frames[1:], duration=100, loop=0)\n",
    "\n",
    "# Display the first frame (most noisy) for reference\n",
    "plt.imshow(frames[0])\n",
    "plt.axis('off')\n",
    "plt.title(\"Most Noisy Frame\")\n",
    "plt.show()\n",
    "\n",
    "# Display the last frame (most denoised) for reference\n",
    "plt.imshow(frames[-1])\n",
    "plt.axis('off')\n",
    "plt.title(\"Most Denoised Frame\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure that you've loaded the model weights and set the model to eval mode as shown in your code:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnn_model\u001b[49m\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/context_model_31.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[1;32m      3\u001b[0m nn_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Assume noisy_image is a tensor representing the noisy cat image (3, height, height)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Ensure that you've loaded the model weights and set the model to eval mode as shown in your code:\n",
    "nn_model.load_state_dict(torch.load(f\"{save_dir}/context_model_31.pth\", map_location=device))\n",
    "nn_model.eval()\n",
    "\n",
    "# Assume noisy_image is a tensor representing the noisy cat image (3, height, height)\n",
    "noisy_image = torch.randn(1, 3, height, height).to(device)  # Replace this with your actual noisy image\n",
    "\n",
    "# Sample without context or with your desired context (for example, using the same random context):\n",
    "ctx = F.one_hot(torch.randint(0, 5, (1,)), 5).to(device=device).float()\n",
    "\n",
    "# Perform the denoising using DDIM\n",
    "@torch.no_grad()\n",
    "def denoise_noise_cat_image(noisy_image, context, n_steps=25):\n",
    "    samples = noisy_image\n",
    "    intermediate = []\n",
    "    step_size = timesteps // n_steps\n",
    "\n",
    "    for i in range(timesteps, 0, -step_size):\n",
    "        print(f'Denoising timestep {i:3d}', end='\\r')\n",
    "\n",
    "        t = torch.tensor([i / timesteps])[:, None, None, None].to(device)\n",
    "\n",
    "        # Predict noise\n",
    "        eps = nn_model(samples, t, c=context)\n",
    "        \n",
    "        # Denoise\n",
    "        samples = denoise_ddim(samples, i, i - step_size, eps)\n",
    "        intermediate.append(samples.detach().cpu().numpy())\n",
    "\n",
    "    intermediate = np.stack(intermediate)\n",
    "    return samples, intermediate\n",
    "\n",
    "# Call the denoise function\n",
    "denoised_image, intermediate_images = denoise_noise_cat_image(noisy_image, ctx)\n",
    "\n",
    "# Visualize the final denoised image (the last image in the sequence)\n",
    "final_image = denoised_image.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "plt.imshow((final_image * 255).astype(np.uint8))  # Assuming the output is in [0, 1] range\n",
    "plt.show()\n",
    "\n",
    "# Optionally, you can visualize the intermediate steps as an animation if needed\n",
    "animation_ddim = plot_sample(intermediate_images, 1, 1, save_dir, \"denoise_ani\", None, save=False)\n",
    "HTML(animation_ddim.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.0058\n",
      "Epoch 2/5, Loss: 0.0059\n",
      "Epoch 3/5, Loss: 0.0052\n",
      "Epoch 4/5, Loss: 0.0045\n",
      "Epoch 5/5, Loss: 0.0047\n",
      "Model saved to ddpm_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Define UNet model\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, 3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Linear beta schedule function\n",
    "def linear_beta_schedule(timesteps):\n",
    "    # A simple linear schedule for beta values between 0.0001 and 0.02\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "# Function to load MNIST dataset\n",
    "def load_mnist(batch_size):\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "# Save model function\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "# Forward diffusion function\n",
    "def forward_diffusion(x, t, noise_schedule):\n",
    "    alpha_t = noise_schedule[t]\n",
    "    sqrt_alpha_cumprod = torch.sqrt(alpha_t).view(-1, 1, 1, 1)  # Reshape to match batch dimensions\n",
    "    noise = torch.randn_like(x)  # Generate noise with the same shape as x\n",
    "\n",
    "    noisy_image = sqrt_alpha_cumprod * x + torch.sqrt(1.0 - alpha_t).view(-1, 1, 1, 1) * noise\n",
    "    return noisy_image, noise\n",
    "\n",
    "# Training loop\n",
    "def train_ddpm(model, dataloader, noise_schedule, optimizer, timesteps, epochs):\n",
    "    criterion = nn.MSELoss()\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch, _ in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            t = torch.randint(0, timesteps, (batch.size(0),), device=device)  # Random timesteps\n",
    "            noisy_images, noise = forward_diffusion(batch, t, noise_schedule)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predicted_noise = model(noisy_images)  # Predict the noise\n",
    "            loss = criterion(predicted_noise, noise)  # Calculate MSE loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Main function to train and save the model\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Hyperparameters\n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "    timesteps = 500\n",
    "    img_size = 28\n",
    "\n",
    "    # Model and optimizer\n",
    "    model = UNet().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Noise schedule\n",
    "    noise_schedule = linear_beta_schedule(timesteps).to(device)\n",
    "\n",
    "    # Load MNIST data\n",
    "    dataloader = load_mnist(batch_size)\n",
    "\n",
    "    # Train the model\n",
    "    train_ddpm(model, dataloader, noise_schedule, optimizer, timesteps, epochs)\n",
    "\n",
    "    # Save the model after training\n",
    "    save_model(model, \"ddpm_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ddpm_model.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Define UNet model\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, 3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Linear beta schedule for noise\n",
    "def linear_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "# Forward diffusion function\n",
    "def forward_diffusion(x, t, noise_schedule):\n",
    "    alpha_t = noise_schedule[t]\n",
    "    sqrt_alpha_cumprod = torch.sqrt(alpha_t).view(-1, 1, 1, 1)  # Reshape to match batch dimensions\n",
    "    noise = torch.randn_like(x)  # Generate noise with the same shape as x\n",
    "\n",
    "    noisy_image = sqrt_alpha_cumprod * x + torch.sqrt(1.0 - alpha_t).view(-1, 1, 1, 1) * noise\n",
    "    return noisy_image, noise\n",
    "\n",
    "# Reverse process function\n",
    "def reverse_process(model, noisy_image, timesteps, noise_schedule):\n",
    "    # Start from the noisy image and progressively denoise it\n",
    "    with torch.no_grad():\n",
    "        x_t = noisy_image\n",
    "        for t in reversed(range(timesteps)):\n",
    "            # Predict the noise and subtract it from the noisy image\n",
    "            predicted_noise = model(x_t)\n",
    "            alpha_t = noise_schedule[t]\n",
    "            sqrt_alpha_t = torch.sqrt(alpha_t).view(-1, 1, 1, 1)\n",
    "            sqrt_1_minus_alpha_t = torch.sqrt(1.0 - alpha_t).view(-1, 1, 1, 1)\n",
    "            \n",
    "            # Update x_t using the predicted noise\n",
    "            x_t = (x_t - sqrt_1_minus_alpha_t * predicted_noise) / sqrt_alpha_t\n",
    "\n",
    "        return x_t\n",
    "\n",
    "# Load model function\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {path}\")\n",
    "\n",
    "# Load and process cat.png\n",
    "def load_cat_image(path, img_size):\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    img = img.resize((img_size, img_size))\n",
    "    img = np.array(img) / 255.0\n",
    "    img = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "    return img\n",
    "\n",
    "# Main function to load model and use it on cat_3.png\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Hyperparameters\n",
    "    timesteps = 500\n",
    "    img_size = 28\n",
    "\n",
    "    # Model setup\n",
    "    model = UNet().to(device)\n",
    "    load_model(model, \"ddpm_model.pth\")\n",
    "\n",
    "    # Define the noise schedule\n",
    "    noise_schedule = linear_beta_schedule(timesteps).to(device)\n",
    "\n",
    "    # Load and noise cat.png\n",
    "    cat_image = load_cat_image(\"cat_3.png\", img_size).to(device)\n",
    "    noisy_cat, _ = forward_diffusion(cat_image, timesteps - 1, noise_schedule)\n",
    "\n",
    "    # Predict denoised image\n",
    "    denoised_cat = reverse_process(model, noisy_cat, timesteps, noise_schedule)\n",
    "\n",
    "    # Display results\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(cat_image.squeeze().cpu().numpy(), cmap=\"gray\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Noisy\")\n",
    "    plt.imshow(noisy_cat.squeeze().cpu().detach().numpy(), cmap=\"gray\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Denoised\")\n",
    "    plt.imshow(denoised_cat.squeeze().cpu().detach().numpy(), cmap=\"gray\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ImprovedUNet:\n\tMissing key(s) in state_dict: \"encoder.4.weight\", \"encoder.4.bias\", \"decoder.4.weight\", \"decoder.4.bias\". \n\tsize mismatch for middle.0.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for middle.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder.0.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for decoder.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder.2.weight: copying a param with shape torch.Size([1, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for decoder.2.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 98\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Model setup\u001b[39;00m\n\u001b[1;32m     97\u001b[0m model \u001b[38;5;241m=\u001b[39m ImprovedUNet()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 98\u001b[0m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mddpm_model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Define the cosine noise schedule\u001b[39;00m\n\u001b[1;32m    101\u001b[0m noise_schedule \u001b[38;5;241m=\u001b[39m cosine_beta_schedule(timesteps)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[33], line 76\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model, path)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model, path):\n\u001b[0;32m---> 76\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ImprovedUNet:\n\tMissing key(s) in state_dict: \"encoder.4.weight\", \"encoder.4.bias\", \"decoder.4.weight\", \"decoder.4.bias\". \n\tsize mismatch for middle.0.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for middle.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder.0.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for decoder.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder.2.weight: copying a param with shape torch.Size([1, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for decoder.2.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([64])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Improved UNet model with deeper layers\n",
    "class ImprovedUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedUNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, 3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder[0:2](x)\n",
    "        x2 = self.encoder[2:4](x1)\n",
    "        x3 = self.encoder[4:](x2)\n",
    "        x_middle = self.middle(x3)\n",
    "        x = self.decoder[0:2](x_middle)\n",
    "        x = self.decoder[2:](x)\n",
    "        return x\n",
    "\n",
    "# Cosine beta schedule for noise\n",
    "def cosine_beta_schedule(timesteps):\n",
    "    s = torch.linspace(0, timesteps-1, timesteps)\n",
    "    alphas_cumprod = torch.cos((s / (timesteps - 1)) * (np.pi / 2))**2\n",
    "    betas = 1 - alphas_cumprod[1:] / alphas_cumprod[:-1]\n",
    "    betas = torch.clip(betas, min=0.0001, max=0.02)  # Clip to reasonable values\n",
    "    return torch.cat([torch.tensor([0.0001]), betas])\n",
    "\n",
    "# Forward diffusion function with adjustable noise levels\n",
    "def forward_diffusion(x, t, noise_schedule, p):\n",
    "    alpha_t = noise_schedule[t]\n",
    "    sqrt_alpha_cumprod = torch.sqrt(alpha_t).view(-1, 1, 1, 1)  # Reshape to match batch dimensions\n",
    "    noise = torch.randn_like(x)  # Generate noise with the same shape as x\n",
    "    \n",
    "    # Adjust noise level based on probability p\n",
    "    noisy_image = sqrt_alpha_cumprod * x + torch.sqrt(1.0 - alpha_t).view(-1, 1, 1, 1) * noise * p\n",
    "    return noisy_image, noise\n",
    "\n",
    "# Reverse process function\n",
    "def reverse_process(model, noisy_image, timesteps, noise_schedule):\n",
    "    with torch.no_grad():\n",
    "        x_t = noisy_image\n",
    "        for t in reversed(range(timesteps)):\n",
    "            # Predict the noise and subtract it from the noisy image\n",
    "            predicted_noise = model(x_t)\n",
    "            alpha_t = noise_schedule[t]\n",
    "            sqrt_alpha_t = torch.sqrt(alpha_t).view(-1, 1, 1, 1)\n",
    "            sqrt_1_minus_alpha_t = torch.sqrt(1.0 - alpha_t).view(-1, 1, 1, 1)\n",
    "            \n",
    "            # Update x_t using the predicted noise\n",
    "            x_t = (x_t - sqrt_1_minus_alpha_t * predicted_noise) / sqrt_alpha_t\n",
    "\n",
    "        return x_t\n",
    "\n",
    "# Load model function\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {path}\")\n",
    "\n",
    "# Load and process cat.png\n",
    "def load_cat_image(path, img_size):\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    img = img.resize((img_size, img_size))\n",
    "    img = np.array(img) / 255.0\n",
    "    img = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "    return img\n",
    "\n",
    "# Main function to load model and use it on cat_3.png\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Hyperparameters\n",
    "    timesteps = 500\n",
    "    img_size = 28\n",
    "\n",
    "    # Model setup\n",
    "    model = ImprovedUNet().to(device)\n",
    "    load_model(model, \"ddpm_model.pth\")\n",
    "\n",
    "    # Define the cosine noise schedule\n",
    "    noise_schedule = cosine_beta_schedule(timesteps).to(device)\n",
    "\n",
    "    # Load the original cat image\n",
    "    cat_image = load_cat_image(\"cat_3.png\", img_size).to(device)\n",
    "\n",
    "    # Set different noise levels to test\n",
    "    noise_levels = [0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "    # Display results for each noise level\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i, p in enumerate(noise_levels):\n",
    "        # Apply forward diffusion with the current noise level\n",
    "        noisy_cat, _ = forward_diffusion(cat_image, timesteps - 1, noise_schedule, p)\n",
    "\n",
    "        # Predict denoised image\n",
    "        denoised_cat = reverse_process(model, noisy_cat, timesteps, noise_schedule)\n",
    "\n",
    "        # Plot the original, noisy, and denoised images\n",
    "        plt.subplot(4, 3, 3 * i + 1)\n",
    "        plt.title(f\"Original\")\n",
    "        plt.imshow(cat_image.squeeze().cpu().numpy(), cmap=\"gray\")\n",
    "\n",
    "        plt.subplot(4, 3, 3 * i + 2)\n",
    "        plt.title(f\"Noisy (p={p})\")\n",
    "        plt.imshow(noisy_cat.squeeze().cpu().detach().numpy(), cmap=\"gray\")\n",
    "\n",
    "        plt.subplot(4, 3, 3 * i + 3)\n",
    "        plt.title(f\"Denoised (p={p})\")\n",
    "        plt.imshow(denoised_cat.squeeze().cpu().detach().numpy(), cmap=\"gray\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define UNet model for DDPM\n",
    "def conv_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(out_channels)\n",
    "    )\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            conv_block(1, 64),\n",
    "            conv_block(64, 128),\n",
    "            conv_block(128, 256)\n",
    "        )\n",
    "        self.middle = conv_block(256, 512)\n",
    "        self.decoder = nn.Sequential(\n",
    "            conv_block(512, 256),\n",
    "            conv_block(256, 128),\n",
    "            conv_block(128, 64),\n",
    "            nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        middle = self.middle(encoded)\n",
    "        decoded = self.decoder(middle)\n",
    "        return decoded\n",
    "\n",
    "# Forward and backward diffusion functions\n",
    "def forward_diffusion(x_0, t, betas):\n",
    "    noise = torch.randn_like(x_0)\n",
    "    sqrt_alpha_cumprod = torch.sqrt(1 - betas.cumsum(0))\n",
    "    sqrt_one_minus_alpha_cumprod = torch.sqrt(betas.cumsum(0))\n",
    "    return sqrt_alpha_cumprod[t] * x_0 + sqrt_one_minus_alpha_cumprod[t] * noise, noise\n",
    "\n",
    "def sample_timesteps(n_samples, T):\n",
    "    return torch.randint(0, T, (n_samples,), device=device)\n",
    "\n",
    "# Training and generation setup\n",
    "def train_ddpm(model, dataloader, T, betas, epochs=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x in tqdm(dataloader):\n",
    "            x = x.to(device)\n",
    "            t = sample_timesteps(x.size(0), T)\n",
    "\n",
    "            noisy_x, noise = forward_diffusion(x, t, betas)\n",
    "            predicted_noise = model(noisy_x)\n",
    "            \n",
    "            loss = mse_loss(predicted_noise, noise)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "def generate_images(model, x_shape, T, betas):\n",
    "    model.eval()\n",
    "    generated_image = torch.randn(x_shape, device=device)\n",
    "    sqrt_alpha_cumprod = torch.sqrt(1 - betas.cumsum(0))\n",
    "    sqrt_one_minus_alpha_cumprod = torch.sqrt(betas.cumsum(0))\n",
    "\n",
    "    for t in reversed(range(T)):\n",
    "        pred_noise = model(generated_image)\n",
    "        generated_image = (generated_image - sqrt_one_minus_alpha_cumprod[t] * pred_noise) / sqrt_alpha_cumprod[t]\n",
    "\n",
    "    return generated_image\n",
    "\n",
    "# Initialize model and hyperparameters\n",
    "T = 1000\n",
    "betas = torch.linspace(1e-4, 0.02, T)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNet().to(device)\n",
    "\n",
    "# Load and preprocess `cat.png`\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "image = Image.open(\"cat.png\")\n",
    "image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "# Add noise to `cat.png`\n",
    "noisy_image, _ = forward_diffusion(image, T // 2, betas)  # Adding noise at step T/2\n",
    "save_image(noisy_image, \"noisy_cat.png\")\n",
    "\n",
    "# Denoise `cat.png`\n",
    "def denoise_image(model, noisy_image, T, betas):\n",
    "    model.eval()\n",
    "    sqrt_alpha_cumprod = torch.sqrt(1 - betas.cumsum(0))\n",
    "    sqrt_one_minus_alpha_cumprod = torch.sqrt(betas.cumsum(0))\n",
    "\n",
    "    for t in reversed(range(T)):\n",
    "        pred_noise = model(noisy_image)\n",
    "        noisy_image = (noisy_image - sqrt_one_minus_alpha_cumprod[t] * pred_noise) / sqrt_alpha_cumprod[t]\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "# Denoise the image\n",
    "restored_image = denoise_image(model, noisy_image, T, betas)\n",
    "save_image(restored_image, \"denoised_cat.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
